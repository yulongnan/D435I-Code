{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 库文件导入 \r\n",
    "import pyrealsense2 as rs  #D435I库\r\n",
    "import numpy as np\r\n",
    "import cv2\r\n",
    "import os\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 配置深度和彩色数据流\r\n",
    "start = time.time()              #记录程序运行起始时间\r\n",
    "pipeline = rs.pipeline()         #定义通道变量，简化缩写\r\n",
    "config = rs.config()             #数据流配置简写，允许管道用户为管道流以及设备选择和配置请求过滤器\r\n",
    "#config.enable_all_streams()     #显示启用所有设备流\r\n",
    "config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)   #显示启用深度流，30是帧率\r\n",
    "config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)  #显示启用彩色流\r\n",
    "config.enable_stream(rs.stream.infrared, 1, 1280, 720, rs.format.y8, 30) #显示启用红外流1\r\n",
    "config.enable_stream(rs.stream.infrared, 2, 1280, 720, rs.format.y8, 30) #显示启用红外流1\r\n",
    "#开始采集\r\n",
    "profile = pipeline.start(config)\r\n",
    "cv2.waitKey(1000)     # 等待时间(ms) = 获取图像，realsense刚启动的时候图像会有一些失真\r\n",
    "# 深度图像向彩色对齐\r\n",
    "align_to_color = rs.align(rs.stream.color)#简化缩写"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===获得文件最大序号值===#\r\n",
    "def Get_IMG_SeqNum(root = './', img_suffix = '.png', img_name_start = 'color', img_name_startnum = 5):\r\n",
    "    # root = './'  #指定目录\r\n",
    "    Seq_num_Png = []\r\n",
    "    for files in os.listdir(root):\r\n",
    "        if (os.path.splitext(files)[1]== img_suffix) & (os.path.splitext(files)[0][:img_name_startnum]==img_name_start):  \r\n",
    "            Seq_num_Png.append(int(os.path.splitext(files)[0][-6:]))\r\n",
    "    if ~len(Seq_num_Png):  #列表为空 返回0  \r\n",
    "        Seq_num_Png.append(0) \r\n",
    "    return max(Seq_num_Png) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth Scale is:  0.0010000000474974513\n"
     ]
    }
   ],
   "source": [
    "#===深度像素单位 与 分割距离定义===#\r\n",
    "# Getting the depth sensor's depth scale (see rs-align example for explanation)\r\n",
    "depth_sensor = profile.get_device().first_depth_sensor()\r\n",
    "depth_scale = depth_sensor.get_depth_scale()\r\n",
    "print(\"Depth Scale is: \" , depth_scale)\r\n",
    "\r\n",
    "# We will be removing the background of objects more than\r\n",
    "# clipping_distance_in_meters meters away\r\n",
    "clipping_distance_in_meters = 1       #1 meter\r\n",
    "clipping_distance = clipping_distance_in_meters / depth_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 等待连贯的帧:深度和颜色\r\n",
    "frames = pipeline.wait_for_frames()\r\n",
    "# 在上面稳定的帧上运行对齐算法以获得一组对齐的图像  对齐是指RGB+D\r\n",
    "frames = align_to_color.process(frames)\r\n",
    "# 从上面的对齐图像中抽出深度图像和彩色图像\r\n",
    "depth_frame = frames.get_depth_frame()\r\n",
    "color_frame = frames.get_color_frame()\r\n",
    "#判断是否两个图像是否有图像 \r\n",
    "if not depth_frame or not color_frame:\r\n",
    "    print(\"NO depth_frame or NO color_frame\") \r\n",
    "#将D图像转换为伪彩色图像 \r\n",
    "# 将RGB与D图像转换为numpy数组\r\n",
    "depth_image = np.asanyarray(depth_frame.get_data())\r\n",
    "color_image = np.asanyarray(color_frame.get_data())\r\n",
    "# 在深度图像上应用伪彩色图像算法(图像必须通过cv2.convertScaleAbs转换为每像素8位) \r\n",
    "depth_colormap = cv2.applyColorMap(cv2.convertScaleAbs(depth_image, alpha=0.03), cv2.COLORMAP_JET) \r\n",
    "\r\n",
    "#===图像显示===#\r\n",
    "# 将两幅图像举证就行行连接 \r\n",
    "images = np.hstack((color_image, depth_colormap)) \r\n",
    "# 合成的图像进行显示 \r\n",
    "cv2.namedWindow('Align Example', cv2.WINDOW_NORMAL)  # 窗口大小保持比例\r\n",
    "cv2.imshow('Align Example', images) \r\n",
    "key = cv2.waitKey(1) # 等待时间(ms)或按键 \r\n",
    "\r\n",
    "#===图像保存===#\r\n",
    "#时间记录   #固定序号\r\n",
    "localtime =time.localtime(time.time()) \r\n",
    "tname = time.strftime(\"%Y%m%d_%H%M%S\", time.localtime()) \r\n",
    "# 图片计数序号\r\n",
    "Fig_CNT_Seq = Get_IMG_SeqNum() + 1 \r\n",
    "str_Fig_CNT_Seq = '_' + str(Fig_CNT_Seq).zfill(6) \r\n",
    "\r\n",
    "cv2.imwrite('color' + str_Fig_CNT_Seq +'.png', color_image) \r\n",
    "cv2.imwrite('depth' + str_Fig_CNT_Seq +'.png', depth_image) \r\n",
    "cv2.imwrite('depth_cMAP' + str_Fig_CNT_Seq +'.png', depth_colormap) \r\n",
    "\r\n",
    "#===图像np数据===#\r\n",
    "np.save(file = './Image_NPY/'+'depth'+ str_Fig_CNT_Seq +'.npy', arr = depth_image) \r\n",
    "np.save(file = './Image_NPY/'+'color'+ str_Fig_CNT_Seq +'.npy', arr = color_image) \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===关闭摄像头 与 窗口===#\r\n",
    "Flag_OFFCamer = 1  \r\n",
    "if Flag_OFFCamer:\r\n",
    "    cv2.destroyAllWindows()\r\n",
    "    pipeline.stop()\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===独立数据 = 处理环节===#    \r\n",
    "depth_scale = 0.0010000000474974513 \r\n",
    "clipping_distance_in_meters = 1       #1 meter\r\n",
    "clipping_distance = clipping_distance_in_meters / depth_scale\r\n",
    "\r\n",
    "Seq_num = 1\r\n",
    "color_image_npy = np.load(file = './Image_NPY/'+'color_'+ str(Seq_num).zfill(6) +'.npy')\r\n",
    "deep_image_npy = np.load(file = './Image_NPY/'+'depth_'+ str(Seq_num).zfill(6) +'.npy')\r\n",
    "deep_image_npy_cMAP = cv2.applyColorMap(cv2.convertScaleAbs(deep_image_npy, alpha=0.03), cv2.COLORMAP_JET)\r\n",
    "\r\n",
    "deep_image_npy_3d = np.dstack((deep_image_npy, deep_image_npy, deep_image_npy))\r\n",
    "gray_color = np.ones_like(color_image_npy) * 153\r\n",
    "backg_remove = np.where( (deep_image_npy_3d > clipping_distance) | (deep_image_npy_3d < 0) , gray_color , color_image_npy )\r\n",
    "\r\n",
    "\r\n",
    "images = np.hstack((backg_remove, deep_image_npy_cMAP))\r\n",
    "\r\n",
    "\r\n",
    "cv2.namedWindow('Align Example', cv2.WINDOW_KEEPRATIO)  # 窗口大小保持比例\r\n",
    "cv2.imshow('Align Example', images)\r\n",
    "\r\n",
    "\r\n",
    "# Press esc or 'q' to close the image window\r\n",
    "while True:\r\n",
    "    key = cv2.waitKey(1)\r\n",
    "    if key & 0xFF == ord('q') or key == 27:\r\n",
    "        cv2.destroyAllWindows()\r\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}